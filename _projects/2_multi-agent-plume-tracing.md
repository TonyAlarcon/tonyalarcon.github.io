---
layout: page
title: Multi-Agent Reinforcement Learning for Plume Tracing
description: Fault-aware, uncertainty-tolerant MARL for multi-source plume localization.
img: assets/img/publication_preview/plume_tracing_thumbnail.png
importance: 2
category: work
github: https://github.com/TonyAlarcon/ADDRQN-MARL-Plume-Tracing
---

This project studies **multi-agent reinforcement learning (MARL)** for locating and tracing multiple hazardous plumes with UAV teams in realistic conditions.
The core focus is on an architectural design that supports **uncertainty handling, robustness, and recovery** when agents face common UAV faults during mission execution.

Instead of assuming perfect sensors and fault-free dynamics, the framework evaluates coordinated decision-making under noisy measurements, changing plume fields, and degraded agent capability.
The result is a more deployment-oriented MARL workflow that emphasizes reliability and mission completion quality, not just idealized benchmark performance.

The experiments examine how policy design and coordination strategy affect search efficiency, source localization quality, and fault tolerance across challenging scenarios.

**Project links**

- Paper (DOI): [Multi-source plume tracing via multi-agent reinforcement learning under Common UAV-faults](https://doi.org/10.1016/j.mlwa.2025.100737)
- Preprint (arXiv): [arXiv:2505.08825](https://arxiv.org/abs/2505.08825)
- Code: [ADDRQN-MARL-Plume-Tracing](https://github.com/TonyAlarcon/ADDRQN-MARL-Plume-Tracing)
